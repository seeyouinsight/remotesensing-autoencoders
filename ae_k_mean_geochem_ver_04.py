# -*- coding: utf-8 -*-
"""AE_K-Mean_GeoChem_ver_04.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FtsuV1Wjpkd5ZFzFziXdMy9oEypcTDbr

# Autoencoder and K-means

# Dimensionality reduction with Autoencoders versus PCA
"""

!pip install spectral
!pip install rasterio

from google.colab import drive
drive.mount('/content/drive')

"""## Use [rasterio](https://rasterio.readthedocs.io/en/latest/) package to open images.

Geographic information systems use GeoTIFF and other formats to organize and store gridded raster datasets such as satellite imagery and terrain models. Rasterio reads and writes these formats and provides a Python API based on Numpy N-dimensional arrays and GeoJSON.
"""

# Basic import

from time import time
import rasterio as rio
from sklearn.preprocessing import minmax_scale
from sklearn import cluster
from sklearn.decomposition import PCA

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow import keras

# reading the HSI images (dataset)
# X, y = datasets.make_classification(n_samples=10000, n_features=50, n_redundant=10, n_informative=10,
                          #  random_state=1, n_clusters_per_class=2,n_classes=3, class_sep=2)
                           
# # divide data in Train - Validation - Test
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
# X_tr, X_valid, y_tr, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42) 

# # Standardize Data
# sc = StandardScaler()
# X_tr_std = sc.fit_transform(X_tr)
# X_valid_std = sc.transform(X_valid)
# X_test_std = sc.transform(X_test)

"""## Load and process Dataset 

Hyperspectral Image(HSI) data often contains hundreds of spectral bands over the same spatial area which provide valuable information to identify the various materials. In HSI, each pixel can be regarded as a high dimensional vector whose entries correspond to the spectral reflectance from visible to infrared.

## Visualizing the data

Hyper-spectral image (HSI) satellite
"""

!pip install hyperspy

import hyperspy.api as hs
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image

img_15 = Image.open('drive/MyDrive/VAE_GeoChem/Wilcannia_RockUnits_15m.tif')
img_30 = Image.open('drive/MyDrive/VAE_GeoChem/Wilcannia_RockUnits_30m.tif')
# Loading data
# s = hs.load("drive/MyDrive/VAE_GeoChem/Wilcannia_RockUnits_15m.tif")

# img.save("drive/MyDrive/VAE_GeoChem/Wilcannia_RockUnits_30m.png")
img_15

# im = Image.open('tmp.png')
# im.show()

img_30

# Importing the data
import rasterio as rio
data_raster = rio.open('drive/MyDrive/VAE_GeoChem/Playa_Image.tif')
data_test   = rio.open('drive/MyDrive/VAE_GeoChem/Playa_Training.tif')

# data_raster = rio.open('drive/MyDrive/VAE_GeoChem/Wilcannia_ASTER.tif')
# data_test   = rio.open('drive/MyDrive/VAE_GeoChem/Wilcannia_RockUnits_15m.tif')
# print(data_raster.meta)
# Wilcannia_ASTER.tif
# Wilcannia_RockUnits_15m.tif
## Visualizing the data
# Reading and enhancing
data_array = data_raster.read() # reading the data
vmin, vmax = np.nanpercentile(data_array, (1,99)) # 5-95% pixel values stretch

data_array_test = data_test.read() # reading the data
vmin, vmax = np.nanpercentile(data_array_test, (1,99)) # 5-95% pixel values stretch
# Plotting the enhanced image
# fig = plt.figure(figsize=[20,20])
# plt.axis('off')
# plt.imshow(data_array[0, :, :], vmin=vmin, vmax=vmax)
# plt.show()

"""### Reshaping the `train data` from brc to rcb Creating an empty array with the same dimension and data type.

Extracting pixels of the HSI is one of the important preprocessing tasks. This makes easier to handle the data and also to implement machine learning algorithms such as classification, clustering e.t.c
"""

imgxyb = np.empty((data_raster.height, data_raster.width, data_raster.count), data_raster.meta['dtype'])
# Looping through the bands to fill the empty array
for band in range(imgxyb.shape[2]):
    imgxyb[:,:,band] = data_raster.read(band+1)

# Reshaping the train data from rcb to samples and features
data_reshaped = imgxyb.reshape(imgxyb.shape[0]*imgxyb.shape[1], -1)
# Scaling
data_reshaped = minmax_scale(data_reshaped, feature_range=(0, 1), axis=0, copy=False)
data_reshaped.shape

"""### Reshaping the `test data` from brc to rcb Creating an empty array with the same dimension and data type"""

imgxyb_test = np.empty((data_test.height, data_test.width, data_test.count), data_test.meta['dtype'])
# Looping through the bands to fill the empty array
for band in range(imgxyb_test.shape[2]):
    imgxyb_test[:,:,band] = data_test.read(band+1)

# Reshaping the test data from rcb to samples and features
data_reshaped_test = imgxyb_test.reshape(imgxyb_test.shape[0]*imgxyb_test.shape[1], -1)
# Scaling
data_reshaped_test = minmax_scale(data_reshaped, feature_range=(0, 1), axis=0, copy=False)
data_reshaped_test.shape

"""## Data split: Train - Validation - Test

The procedure involves taking a dataset and dividing it into two subsets. The first subset is used to fit the model and is referred to as the training dataset. The second subset is not used to train the model; instead, the input element of the dataset is provided to the model, then predictions are made and compared to the expected values. This second dataset is referred to as the test dataset.



*   Train Dataset: Used to fit the machine learning model.
*   Test Dataset: Used to evaluate the fit machine learning model.


"""

# divide data in Train - Validation - Test
X_train, X_test, y_train, y_test = train_test_split(data_reshaped, data_reshaped_test, test_size=0.3, random_state=42)
X_tr, X_valid, y_tr, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

"""###  Standardize Data:

the process of converting data to a common format to enable users to process and analyze it

"""

sc = StandardScaler()
X_tr_std = sc.fit_transform(X_tr)
X_valid_std = sc.transform(X_valid)
X_test_std = sc.transform(X_test)

print(X_tr_std)

"""## Let’s set up  Auto-encoderE: """

# Encoder (input bands)7-7-7-7-7-7-7-6-5
encoder = keras.models.Sequential([
    keras.layers.Dense(7, input_shape=[7]),
    keras.layers.Dense(7, input_shape=[7]),
    keras.layers.Dense(7, input_shape=[7]),
    keras.layers.Dense(7, input_shape=[7]),
    keras.layers.Dense(7, input_shape=[7]),
    keras.layers.Dense(7, input_shape=[7]),
    keras.layers.Dense(6, input_shape=[7]),
    keras.layers.Dense(5, input_shape=[6]),
])

# Decoder 5-6-7-7-7-7-7-7-7 (output dimension/bands)
decoder = keras.models.Sequential([
    keras.layers.Dense(6, input_shape=[5]),
    keras.layers.Dense(7, input_shape=[6]),
    keras.layers.Dense(7, input_shape=[7]),
    keras.layers.Dense(7, input_shape=[7]),
    keras.layers.Dense(7, input_shape=[7]),
    keras.layers.Dense(7, input_shape=[7]),
    keras.layers.Dense(7, input_shape=[7]),
    keras.layers.Dense(7, input_shape=[7]),
])

# define the auto-encoder model
autoencoder = keras.models.Sequential([encoder, decoder])
autoencoder.compile(loss='mse', optimizer = keras.optimizers.SGD(learning_rate=0.01))

# epochs (hyperparameter)
epochs = 20

# saving the loss in history 
history = autoencoder.fit(X_tr_std,X_tr_std, epochs=epochs,validation_data=(X_valid_std,X_valid_std),
                         callbacks=[keras.callbacks.EarlyStopping(patience=10)])
# train the Auto-encoder model                        
codings = encoder.predict(X_tr_std)

autoencoder.summary()

autoencoder.count_params()

print(history.history.keys())

print(len(history.history['loss']))
train_loss_val = history.history['loss']
test_loss_val = history.history['val_loss']

train_loss = [i * 1000 for i in train_loss_val]
test_loss  = [i * 1000 for i in test_loss_val]

"""## plot the train and validation loss"""

pd.DataFrame(history.history).plot(figsize=(8,5))
plt.ylabel('Loss * 1000')
plt.xlabel('Epochs')
plt.savefig("summarize history for loss.jpg")



pd.DataFrame(history.history).plot(figsize=(8,5))
plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.savefig("summarize history for loss.jpg")

"""## PCA implementation: [paper](https://www.sciencedirect.com/science/article/pii/S1877050919321507)

PCA  finds low dimensional approximations to the data by
projecting the data onto linear subspaces

Principal Components Analysis (PCA)
1. Compute the sample covariance matrix Σ =b n
−1 Pn
i=1(Xi − Xn)(Xi − Xn)
T
.
2. Compute the eigenvalues λ1 ≥ λ2 ≥ · · · and eigenvectors e1, e2, . . . , of Σ. b
3. Choose a dimension k.
4. Define the dimension reduced data Zi = Tk(Xi) = X +
Pk
j=1 βijej where βij =
hXi − X, ej i.
"""

from sklearn.decomposition import PCA
# pca = PCA(n_components=5,svd_solver='auto')
# scores = pca.fit_transform(X_tr_std) # u

# PCA
pca = PCA(n_components=data_array.shape[0])
scores = pca.fit_transform(data_reshaped)
var_ratio = pca.explained_variance_ratio_
values = pca.singular_values_

print(var_ratio.shape)
print(values)

"""### function to plot and display the image"""

def plot_data(data,fig_name):
  fig = plt.figure(figsize = (15, 10))
  plt.imshow(data, cmap = 'nipy_spectral')
  plt.colorbar()
  plt.axis('off')
  plt.show()
  plt.savefig(fig_name)

"""# Clustring: [blog](https://developers.google.com/machine-learning/clustering/clustering-algorithms)

Clustering or cluster analysis is a machine learning technique, which groups the unlabelled dataset. It can be defined as "A way of grouping the data points into different clusters, consisting of similar data points.

When choosing a clustering algorithm, you should consider whether the algorithm scales to your dataset. Datasets in machine learning can have millions of examples, but not all clustering algorithms scale efficiently. Many clustering algorithms work by computing the similarity between all pairs of examples. This means their runtime increases as the square of the number of examples , denoted as n in O(nxn) complexity notation.  O(nxn) algorithms are not practical when the number of examples are in millions. Here, we focuses on the **`k-means`** algorithm, which has a complexity of O(n), meaning that the algorithm scales linearly with .

# a. PCA -> K-means
"""

# K-means
cl = cluster.KMeans(n_clusters=5) # Creating an object of the classifier
components_num = 5
param = cl.fit(scores[:,:components_num]) # Training
img_c = cl.labels_ # Getting the labels of the classes
img_cl = img_c.reshape(data_array[0,:,:].shape) # Reshaping the labels to a 3D array (single band)
plot_data(img_cl, 'PCA_k_means.png')

"""## b. *Auto-encoder -> K-means*"""

# K-means
cl = cluster.KMeans(n_clusters=10) # Creating an object of the classifier
param = cl.fit(codings) # Training
img_c = cl.labels_ # Getting the labels of the classes
# img_cl_pred = cl.predict(data_ae)
img_c2 = img_cl.reshape(data_array[0,:,:].shape) # Reshaping the labels to a 3D array (single band)
plot_data(img_c2, 'AE_k_means.png')

codings_train = encoder.predict(X_tr_std)
codings_test = encoder.predict(X_test_std)
scores_train = pca.transform(X_tr_std)
scores_test = pca.transform(X_test_std)

pd.DataFrame(scores_train, columns=['PC'+str(i) for i in range(pca.n_components_)]).std().plot(kind='bar', color='tab:blue')
plt.ylabel('scores std. dev.')
plt.savefig('scores_std_dev.png')
# plt.savefig("PCA.jpg")

pd.DataFrame(codings_train, columns=['E'+str(i) for i in range(5)]).std().plot(kind='bar', color='tab:red') # range(no of components)
plt.ylabel('E-D LVs std. dev.')
plt.savefig('E-D_LVs_std_dev.png')

sns.heatmap(pd.DataFrame(scores_train, columns=['PC'+str(i) for i in range(pca.n_components_)]).corr(), vmin=-1, vmax=+1, cmap='coolwarm', annot=True)

sns.heatmap(pd.DataFrame(codings_train, columns=['E'+str(i) for i in range(5)]).corr(), vmin=-1, vmax=+1, cmap='coolwarm', annot=True)

autoencoder.summary()

"""## NonLinear Stacked Encoder-Decoder
The nonlinear stacked AE will be easily implemented as the stacked AE but with an activation function. We also introduced a decay constant over the SGD optimizer so that the learning rate will decrease over time. We pick “selu” as activation layer for all layers. Note that here we have increased the complexity even more: we could try to find the best number of hidden layers, the best activation function and shape of each of the layers for the specific problem.
"""

nl_st_encoder = keras.models.Sequential([
    keras.layers.Dense(6, input_shape=[7], activation='relu'),
    keras.layers.Dense(5, activation='selu'),
    keras.layers.Dense(5, activation='selu'),
])

nl_st_decoder = keras.models.Sequential([
    keras.layers.Dense(5, input_shape=[5], activation='selu'),
    keras.layers.Dense(6, activation='selu'),
    keras.layers.Dense(7, activation='relu'),
])

nl_st_autoencoder = keras.models.Sequential([nl_st_encoder, nl_st_decoder])
nl_st_autoencoder.compile(loss='mse', optimizer = keras.optimizers.SGD(learning_rate=0.01, decay=1e-4))
nl_st_autoencoder.summary()


history = nl_st_autoencoder.fit(X_tr_std,X_tr_std, epochs=10,validation_data=(X_valid_std,X_valid_std),
                         callbacks=[keras.callbacks.EarlyStopping(patience=10)],verbose=1)

nl_st_codings_train = nl_st_encoder.predict(X_tr_std)
nl_st_codings_test = nl_st_encoder.predict(X_test_std)

"""# Conclusion 
Our aim was to compare PCA and an AutoEncoder neural network to see if the dimensionality reduction was comparable.

- We looked at the properties of the scores/encodings and we saw that encodings from the AE have some correlations (the covariant matrix is not diagonal like in PCA), and also that their standard deviation is similar.
Starting from a simple linear undercomplete AE with just 1 layer, we saw that increasing complexity helped the model reach better performances, evaluated in terms of classification accuracy.
- Finally, we saw that a non linear model can still perform better than the other two (one layer AE and stacked AE) but the performance is still comparable to that of PCA in this dataset.
"""



"""https://github.com/rasbt/deeplearning-models/tree/master/pytorch_ipynb/autoencoder"""



"""# VAE : test"""

import torch; torch.manual_seed(0)
import torch.nn as nn
import torch.nn.functional as F
import torch.utils
import torch.distributions
import torchvision
import numpy as np
import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 200
device = 'cuda' if torch.cuda.is_available() else 'cpu'

class VariationalEncoder(nn.Module):
    def __init__(self, latent_dims):
        super(VariationalEncoder, self).__init__()
        self.linear1 = nn.Linear(7, 6)
        self.linear2 = nn.Linear(5, latent_dims)
        self.linear3 = nn.Linear(5, latent_dims)

        self.N = torch.distributions.Normal(0, 1)
        self.N.loc = self.N.loc.cuda() # hack to get sampling on the GPU
        self.N.scale = self.N.scale.cuda()
        self.kl = 0

    def forward(self, x):
        x = torch.flatten(x, start_dim=1)
        x = F.relu(self.linear1(x))
        mu =  self.linear2(x)
        sigma = torch.exp(self.linear3(x))
        z = mu + sigma*self.N.sample(mu.shape)
        self.kl = (sigma**2 + mu**2 - torch.log(sigma) - 1/2).sum()
        return z

class Decoder(nn.Module):
    def __init__(self, latent_dims):
        super(Decoder, self).__init__()
        self.linear1 = nn.Linear(5, 6)
        self.linear2 = nn.Linear(6, 7)

    def forward(self, z):
        z = F.relu(self.linear1(z))
        z = torch.sigmoid(self.linear2(z))
        return z

class VariationalAutoencoder(nn.Module):
    def __init__(self, latent_dims):
        super(VariationalAutoencoder, self).__init__()
        self.encoder = VariationalEncoder(latent_dims)
        self.decoder = Decoder(latent_dims)

    def forward(self, x):
        z = self.encoder(x)
        return self.decoder(z)

def train(autoencoder, data, epochs=20):
    opt = torch.optim.Adam(autoencoder.parameters())
    for epoch in range(epochs):
        for x, y in data:
            x = x.to(device) # GPU
            opt.zero_grad()
            x_hat = autoencoder(x)
            loss = ((x - x_hat)**2).sum() + autoencoder.encoder.kl
            loss.backward()
            opt.step()
    return autoencoder

vae = VariationalAutoencoder(latent_dims).to(device) # GPU
vae = train(vae, data)









# mnist_vae_viz.py

# PyTorch variational autoencoder visualization
# compress each 9 bands to 5 values then plot


# PyTorch 1.8.0-CPU Anaconda3-2020.02  Python 3.7.6
# CPU, Windows 10

import numpy as np
import torch as T
import matplotlib.pyplot as plt
import torchvision as tv  # to visualize fakes

device = T.device("gpu")

# -----------------------------------------------------------

class dataset_playa():
  # for an Autoencoder (not a classifier)
  # assumes data has been converted to tab-delim text files:
  # 7 pixel values (0-255) (tab) label (0-9)
  # [0] [1] . . [7] [7] 

  def __init__(self, tmp_x,tmp_y):
    # tmp_x = np.loadtxt(src_file, usecols=[784],
    #   deliminp.loadtxt(src_file, usecols=range(0,7),
    #   delimiter="\t", comments="#", dtype=np.float32)
    # tmp_y = ter="\t", comments="#", dtype=np.int64)
    self.x_data = T.tensor(tmp_x, dtype=T.float32).to(device) 
    # self.x_data /= 255.0  # normalize pixels
    self.y_data = T.tensor(tmp_y, dtype=T.int64).to(device)
    # don't normalize digit labels

  def __len__(self):
    return len(self.x_data)

  def __getitem__(self, idx):
    pixels = self.x_data[idx]
    label = self.y_data[idx]
    return (pixels, label)

# -----------------------------------------------------------
# for the dataset (after reshaping the data)

# def dataset_playa(temp_x,tmp_y):
#   
#   x_data = T.tensor(tmp_x, dtype=T.float32).to(device) 
#   x_data /= 255.0  # normalize pixels
#   y_data = T.tensor(temp_y, dtype=T.int64).to(device)
#   return pixels, label

# -----------------------------------------------------------

class VAE(T.nn.Module):  # [7-6-5-[2,2]-2-5-6-7]
  def __init__(self):
    super(VAE, self).__init__()  
    self.fc1a = T.nn.Linear(7, 6)  # no labels
    self.fc1b = T.nn.Linear(6, 5)  # no labels

    self.fc2a = T.nn.Linear(5, 2)   # u
    self.fc2b = T.nn.Linear(5,2)   # log-var


    self.fc3 = T.nn.Linear(2, 5)
    self.fc4a = T.nn.Linear(5, 6) 
    self.fc4b  = T.nn.Linear(6, 7)

  def encode(self, x):              # 7-6-5-[2,2]  
    z = T.relu(self.fc1a(x)) 
    z = T.relu(self.fc1b(z))
    z1 = self.fc2a(z)               # activation here ??
    z2 = self.fc2b(z) 
    return (z1, z2)                 # (u, log-var)

  def decode(self, x):              # 2-5-6-7
    z = T.relu(self.fc3(x))
    z = T.relu(self.fc4a(z))     
    z = T.sigmoid(self.fc4b(z))      # in [0, 1]
    return z 

  def forward(self, x):
    (u, logvar) = self.encode(x)
    stdev = T.exp(0.5 * logvar)
    noise = T.randn_like(stdev)
    z = u + (noise * stdev)         # [2]
    oupt = self.decode(z)
    return (oupt, u, logvar)

# -----------------------------------------------------------

def cus_loss_func(recon_x, x, u, logvar):
  # https://arxiv.org/abs/1312.6114
  # KLD = 0.5 * sum(1 + log(sigma^2) - u^2 - sigma^2)
  # bce = T.nn.functional.binary_cross_entropy(recon_x, \
  #   x.view(-1, 784), reduction="sum")

  # mse = T.nn.functional.mse_loss(recon_x, x.view(-1, 784))
  mse = T.nn.functional.mse_loss(recon_x, x)

  kld = -0.5 * T.sum(1 + logvar - u.pow(2) - \
    logvar.exp())

  BETA = 1.0
  return mse + (BETA * kld)

# -----------------------------------------------------------

def train(vae, ds, bs, me, lr, le):
  # train autoencoder vae with dataset ds using batch size bs, 
  # with max epochs me, learn rate lr, log_every le
  data_ldr = T.utils.data.DataLoader(ds, batch_size=bs,
    shuffle=True)
  
  # loss_func = T.nn.MSELoss() # use custom loss
  opt = T.optim.SGD(vae.parameters(), lr=lr)
  # print(vae.parameters())
  print("Starting training")
  for epoch in range(0, me):
    for (b_idx, batch) in enumerate(data_ldr):
      opt.zero_grad()
      X = batch[0]  # don't use Y labels to train
      recon_x, u, logvar = vae(X)
      loss_val = cus_loss_func(recon_x, X, u, logvar)
      loss_val.backward()
      opt.step()

    if epoch != 0 and epoch % le == 0:
      print("epoch = %6d" % epoch, end="")
      print("  curr batch loss = %7.4f" % loss_val.item(), end="")
      print("")

      # save and view sample images as sanity check
      # num_images = 64
      # rinpt = T.randn(num_images, 2).to(device)
      # with T.no_grad():
      #   fakes = vae.decode(rinpt)
      # fakes = fakes.view(num_images, 1, 28, 28)
      # tv.utils.save_image(fakes,
      #   ".\\Fakes\\fakes_" + str(epoch) + ".jpg",
      #   padding=4, pad_value=1.0) # no overwrite

  print("Training complete ")

# -----------------------------------------------------------
# divide data in Train - Validation - Test
# X_train, X_test, y_train, y_test = train_test_split(data_reshaped, data_reshaped_test, test_size=0.3, random_state=42)
# X_tr, X_valid, y_tr, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42) 


# -----------------------------------------------------------
def main():
  # 0. get started
  print("\nBegin VAE  ")
  T.manual_seed(1)
  np.random.seed(1)

  # 1. create Dataset object
  print("\nCreating  Dataset ")
  # fn = ".\\Data\\mnist_train_10000.txt"
  # data_ds = MNIST_Dataset(fn)           ############## reshaped dataset here.    #############
  data_ds = dataset_playa(X_train,y_train)
  # print(data_ds.shape)
  # 2. create and train VAE model 
  print("\nCreating VAE  \n")
  vae = VAE()   # 7-5-[2,2]-2-5-7
  vae.train()           # set mode

  # Hyperparameters
  bat_size = 10000
  max_epochs = 40
  lrn_rate = 0.1
  log_every = int(max_epochs / 10)
  train(vae, data_ds, bat_size, max_epochs, \
    lrn_rate, log_every)

  # 3. TODO: save trained VAE

  # 4. use model encoder to generate (x,y) pairs
  vae.eval()
  all_pixels = data_ds[0:1000][0]  # all pixel values
  all_labels = data_ds[0:1000][1]

  with T.no_grad():
    u, logvar = vae.encode(all_pixels) # mean logvar

  print("\nImages reduced to 2 values: ")
  print(u)

  # 5. graph the reduced-form digits in 2D
  # print("\nPlotting reduced-dim images")
  # plt.scatter(u[:,0], u[:,1],
  #           c=all_labels, edgecolor='none', alpha=0.9,
  #           cmap=plt.cm.get_cmap('nipy_spectral', 11),
  #           s=20)  # s=20 orig, alpha=0.9
  # plt.xlabel('mean[0]')
  # plt.ylabel('mean[1]')
  # plt.colorbar()
  # plt.show()
  # plt.savefig()

  print("\nEnd VAE")

# -----------------------------------------------------------

if __name__ == "__main__":
  main()



"""# Elbow Method
The KElbowVisualizer implements the “elbow” method to help data scientists select the optimal number of clusters by fitting the model with a range of values for 𝐾. If the line chart resembles an arm, then the “elbow” (the point of inflection on the curve) is a good indication that the underlying model fits best at that point. In the visualizer “elbow” will be annotated with a dashed line.

To demonstrate, in the following example the KElbowVisualizer fits the KMeans model for a range of 𝐾 values from 4 to 11 on a sample two-dimensional dataset with 8 random clusters of points. When the model is fit with 8 clusters, we can see a line annotating the “elbow” in the graph, which in this case we know to be the optimal number.


"""

from sklearn.cluster import KMeans
from sklearn.datasets import make_blobs

from yellowbrick.cluster import KElbowVisualizer

# Generate synthetic dataset with 8 random clusters
X, y = make_blobs(n_samples=1000, n_features=12, centers=8, random_state=42)

# Instantiate the clustering model and visualizer
model = KMeans()
visualizer = KElbowVisualizer(model, k=(3,9))

visualizer.fit(scores[:,:components_num])        # Fit the data to the visualizer
visualizer.show()        # Finalize and render the figure

